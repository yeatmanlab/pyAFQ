
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_bids_layout.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_bids_layout.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_bids_layout.py:


====================
How pyAFQ uses BIDS
====================

The pyAFQ API relies heavily on the
`Brain Imaging Data Standard (BIDS) <https://bids-specification.readthedocs.io/en/stable/>`_. This means that the software assumes that its inputs are organized
according to the BIDS spec and its outputs conform where possible with the
BIDS spec.

.. note::

    Derivatives of processing diffusion MRI are not currently fully
    described in the existing BIDS specification, but describing these
    is part of an ongoing effort. Wherever possible, we conform with
    the draft implementation of the BIDS DWI derivatives available
    `here <https://bids-specification.readthedocs.io/en/wip-derivatives/05-derivatives/05-diffusion-derivatives.html>`_

In this example, we will explore the use of BIDS in pyAFQ and see
how BIDS allows us to extend and provide flexibility to the users
of the software.

.. GENERATED FROM PYTHON SOURCE LINES 24-35

.. code-block:: default


    import os
    import os.path as op

    import matplotlib.pyplot as plt
    import nibabel as nib

    from AFQ.api.group import GroupAFQ
    import AFQ.data.fetch as afd









.. GENERATED FROM PYTHON SOURCE LINES 36-38

To interact with and query BIDS datasets, we use
 `pyBIDS <https://bids-standard.github.io/pybids/>`_.

.. GENERATED FROM PYTHON SOURCE LINES 38-42

.. code-block:: default


    import bids









.. GENERATED FROM PYTHON SOURCE LINES 43-49

We start with some example data. The data we will use here is
generated from the
`Stanford HARDI dataset <https://purl.stanford.edu/ng782rw8378>`_.
The call below fetches
this dataset and organized it within the `~/AFQ_data` folder in the BIDS
format.

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: default


    afd.organize_stanford_data(clear_previous_afq=True)








.. GENERATED FROM PYTHON SOURCE LINES 53-89

After doing that, we should have a folder that looks like this:

| stanford_hardi
| ├── dataset_description.json
| └── derivatives
|     ├── freesurfer
|     │   ├── dataset_description.json
|     │   └── sub-01
|     │       └── ses-01
|     │           └── anat
|     │               ├── sub-01_ses-01_T1w.nii.gz
|     │               └── sub-01_ses-01_seg.nii.gz
|     └── vistasoft
|         ├── dataset_description.json
|         └── sub-01
|             └── ses-01
|                 └── dwi
|                     ├── sub-01_ses-01_dwi.bvals
|                     ├── sub-01_ses-01_dwi.bvecs
|                     └── sub-01_ses-01_dwi.nii.gz

The top level directory is our overall bids dataset folder. In most
cases, this folder will include a `raw` folder that will contain the
raw data. In this case, we do not include the raw folder and only have
the pipelines that contains the outputs of preprocessing the data.
In general, only the preprocessed diffusion data is required.
See the "Organizing your data" section of "Using pyAFQ" for more details.
In this case, one folder containing Freesurfer derivatives and another
folder containing the DWI data that has been preprocessed with Vistasoft.
pyAFQ provides facilities to segment tractography results obtained
using other software. For example, we often use
`qsiprep <https://qsiprep.readthedocs.io/en/latest/>`_ to preprocess
our data and reconstruct tractographies with software such as
`MRTRIX <https://www.mrtrix.org/>`_. Here, we will demonstrate how to use
these reconstructions in the pyAFQ segmentation and tractometry pipeline
We fetch this data and add it as a separate pipeline

.. GENERATED FROM PYTHON SOURCE LINES 89-113

.. code-block:: default


    afd.fetch_stanford_hardi_tractography()

    bids_path = op.join(op.expanduser('~'), 'AFQ_data', 'stanford_hardi')
    tractography_path = op.join(bids_path, 'derivatives', 'my_tractography')
    sub_path = op.join(tractography_path, 'sub-01', 'ses-01', 'dwi')

    os.makedirs(sub_path, exist_ok=True)
    os.rename(
        op.join(
            op.expanduser('~'),
            'AFQ_data',
            'stanford_hardi_tractography',
            'full_segmented_cleaned_tractography.trk'),
        op.join(
            sub_path,
            'sub-01_ses-01-dwi_tractography.trk'))

    afd.to_bids_description(
        tractography_path,
        **{"Name": "my_tractography",
            "PipelineDescription": {"Name": "my_tractography"}})






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|          | 0/11337 [00:00<?, ? MB/s]      0%|          | 4/11337 [00:00<06:40, 28.29 MB/s]      0%|          | 11/11337 [00:00<04:39, 40.47 MB/s]      0%|          | 46/11337 [00:00<01:24, 133.52 MB/s]      2%|1         | 184/11337 [00:00<00:24, 462.39 MB/s]      5%|4         | 548/11337 [00:00<00:08, 1212.41 MB/s]      8%|8         | 916/11337 [00:00<00:06, 1673.88 MB/s]     11%|#1        | 1289/11337 [00:01<00:05, 1979.71 MB/s]     15%|#4        | 1651/11337 [00:01<00:04, 2157.65 MB/s]     18%|#7        | 2027/11337 [00:01<00:04, 2302.92 MB/s]     21%|##1       | 2392/11337 [00:01<00:03, 2377.12 MB/s]     24%|##4       | 2766/11337 [00:01<00:03, 2451.54 MB/s]     28%|##7       | 3140/11337 [00:01<00:03, 2498.81 MB/s]     31%|###       | 3501/11337 [00:01<00:03, 2506.37 MB/s]     34%|###4      | 3871/11337 [00:02<00:02, 2526.65 MB/s]     37%|###7      | 4240/11337 [00:02<00:02, 2545.70 MB/s]     41%|####      | 4611/11337 [00:02<00:02, 2563.05 MB/s]     44%|####3     | 4983/11337 [00:02<00:02, 2574.37 MB/s]     47%|####7     | 5356/11337 [00:02<00:02, 2578.68 MB/s]     50%|#####     | 5713/11337 [00:02<00:02, 2547.01 MB/s]     54%|#####3    | 6081/11337 [00:02<00:02, 2557.68 MB/s]     57%|#####6    | 6456/11337 [00:03<00:01, 2578.13 MB/s]     60%|######    | 6829/11337 [00:03<00:01, 2582.72 MB/s]     64%|######3   | 7200/11337 [00:03<00:01, 2586.92 MB/s]     67%|######6   | 7573/11337 [00:03<00:01, 2591.98 MB/s]     70%|#######   | 7947/11337 [00:03<00:01, 2599.81 MB/s]     73%|#######2  | 8240/11337 [00:03<00:01, 2660.26 MB/s]     75%|#######5  | 8508/11337 [00:03<00:01, 2570.04 MB/s]     78%|#######7  | 8813/11337 [00:03<00:00, 2684.88 MB/s]     80%|########  | 9084/11337 [00:04<00:00, 2585.05 MB/s]     83%|########2 | 9375/11337 [00:04<00:00, 2671.66 MB/s]     85%|########5 | 9645/11337 [00:04<00:00, 2575.13 MB/s]     88%|########7 | 9922/11337 [00:04<00:00, 2627.97 MB/s]     90%|########9 | 10187/11337 [00:04<00:00, 2549.91 MB/s]     92%|#########2| 10457/11337 [00:04<00:00, 2587.54 MB/s]     95%|#########4| 10717/11337 [00:04<00:00, 2485.11 MB/s]     97%|#########7| 11027/11337 [00:04<00:00, 2657.24 MB/s]    100%|#########9| 11295/11337 [00:04<00:00, 2548.46 MB/s]    100%|##########| 11337/11337 [00:04<00:00, 2325.58 MB/s]
      0%|          | 0/14 [00:00<?, ? MB/s]     29%|##8       | 4/14 [00:00<00:00, 28.23 MB/s]     71%|#######1  | 10/14 [00:00<00:00, 36.21 MB/s]    100%|##########| 14/14 [00:00<00:00, 48.87 MB/s]
      0%|          | 0/1037 [00:00<?, ? MB/s]      0%|          | 4/1037 [00:00<00:36, 28.09 MB/s]      2%|1         | 16/1037 [00:00<00:16, 60.92 MB/s]      6%|6         | 67/1037 [00:00<00:04, 196.06 MB/s]     27%|##6       | 275/1037 [00:00<00:01, 692.98 MB/s]     61%|######1   | 636/1037 [00:00<00:00, 1473.09 MB/s]     80%|#######9  | 829/1037 [00:00<00:00, 1585.26 MB/s]    100%|##########| 1037/1037 [00:00<00:00, 1202.60 MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 114-143

After we do that, our dataset folder should look like this:

| stanford_hardi
| ├── dataset_description.json
| └── derivatives
|     ├── freesurfer
|     │   ├── dataset_description.json
|     │   └── sub-01
|     │       └── ses-01
|     │           └── anat
|     │               ├── sub-01_ses-01_T1w.nii.gz
|     │               └── sub-01_ses-01_seg.nii.gz
|     ├── my_tractography
|     |   ├── dataset_description.json
|     │   └── sub-01
|     │       └── ses-01
|     │           └── dwi
|     │               └── sub-01_ses-01-dwi_tractography.trk
|     └── vistasoft
|         ├── dataset_description.json
|         └── sub-01
|             └── ses-01
|                 └── dwi
|                     ├── sub-01_ses-01_dwi.bvals
|                     ├── sub-01_ses-01_dwi.bvecs
|                     └── sub-01_ses-01_dwi.nii.gz

To explore the layout of these derivatives, we will initialize a
:class:`BIDSLayout` class instance to help us see what is in this dataset

.. GENERATED FROM PYTHON SOURCE LINES 143-146

.. code-block:: default


    layout = bids.BIDSLayout(bids_path, derivatives=True)








.. GENERATED FROM PYTHON SOURCE LINES 147-149

Because there is no raw data in this BIDS layout (only derivatives),
pybids will report that there are no subjects and sessions:

.. GENERATED FROM PYTHON SOURCE LINES 149-152

.. code-block:: default


    print(layout)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    BIDS Layout: ...runner/AFQ_data/stanford_hardi | Subjects: 0 | Sessions: 0 | Runs: 0




.. GENERATED FROM PYTHON SOURCE LINES 153-155

But a query on the derivatives will reveal the different derivatives that
are stored here:

.. GENERATED FROM PYTHON SOURCE LINES 155-158

.. code-block:: default


    print(layout.derivatives)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {'vistasoft': BIDS Layout: ...rd_hardi/derivatives/vistasoft | Subjects: 1 | Sessions: 1 | Runs: 0, 'my_tractography': BIDS Layout: ...di/derivatives/my_tractography | Subjects: 1 | Sessions: 1 | Runs: 0, 'freesurfer': BIDS Layout: ...d_hardi/derivatives/freesurfer | Subjects: 1 | Sessions: 1 | Runs: 0}




.. GENERATED FROM PYTHON SOURCE LINES 159-162

We can use a :class:`bids.BIDSValidator` object to make sure that the
files within our data set are BIDS-compliant. For example, we can
extract the tractography derivatives part of our layout using:

.. GENERATED FROM PYTHON SOURCE LINES 162-165

.. code-block:: default


    my_tractography = layout.derivatives["my_tractography"]








.. GENERATED FROM PYTHON SOURCE LINES 166-170

This variable is also a BIDS layout object. This object has a ``get``
method, which allows us to query and find specific items within the
layout. For example, we can ask for files that have a suffix consistent
with tractography results:

.. GENERATED FROM PYTHON SOURCE LINES 170-173

.. code-block:: default


    tractography_files = my_tractography.get(suffix='tractography')








.. GENERATED FROM PYTHON SOURCE LINES 174-175

Or ask for files that have a ``.trk`` extension:

.. GENERATED FROM PYTHON SOURCE LINES 175-178

.. code-block:: default


    tractography_files = my_tractography.get(extension='.trk')








.. GENERATED FROM PYTHON SOURCE LINES 179-180

In this case, both of these would produce the same result.

.. GENERATED FROM PYTHON SOURCE LINES 180-184

.. code-block:: default


    tractography_file = tractography_files[0]
    print(tractography_file)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <BIDSFile filename='/home/runner/AFQ_data/stanford_hardi/derivatives/my_tractography/sub-01/ses-01/dwi/sub-01_ses-01-dwi_tractography.trk'>




.. GENERATED FROM PYTHON SOURCE LINES 185-186

We can also get some more structured information about this file:

.. GENERATED FROM PYTHON SOURCE LINES 186-190

.. code-block:: default


    print(tractography_file.get_entities())






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {'datatype': 'dwi', 'extension': '.trk', 'session': '01', 'subject': '01', 'suffix': 'tractography'}




.. GENERATED FROM PYTHON SOURCE LINES 191-197

We can use a :class:`bids.BIDSValidator` class instance to validate that
this file is compliant with the specification. Note that the validator
requires that the filename be provided relative to the root of the BIDS
dataset, so we have to split the string that contains the full path
of the tractography to extract only the part that is relative to the
root of the entire BIDS ``layout`` object:

.. GENERATED FROM PYTHON SOURCE LINES 197-204

.. code-block:: default


    tractography_full_path = tractography_file.path
    tractography_relative_path = tractography_full_path.split(layout.root)[-1]

    validator = bids.BIDSValidator()
    print(validator.is_bids(tractography_relative_path))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    True




.. GENERATED FROM PYTHON SOURCE LINES 205-212

Next, we specify the information we need to define the bundles that we are
interested in segmenting. In this case, we are going to use a list of
bundle names for the bundle info. These names refer to bundles for
which we already have clear definitions of the information
needed to segment them (e.g., waypoint ROIs and probability maps).
For an example that includes custom definition of bundle info, see the
`plot_callosal_tract_profile example <http://yeatmanlab.github.io/pyAFQ/auto_examples/plot_callosal_tract_profile.html>`_.

.. GENERATED FROM PYTHON SOURCE LINES 212-217

.. code-block:: default


    bundle_info = [
        "SLF_L", "SLF_R", "ARC_L", "ARC_R",
        "CST_L", "CST_R", "FP"]








.. GENERATED FROM PYTHON SOURCE LINES 218-234

Now, we can define our AFQ object, pointing to the derivatives of the
`'my_tractography'` pipeline as inputs. This is done by setting the
`custom_tractography_bids_filters` key-word argument. We pass the
`bundle_info` defined above. We also point to the preprocessed
data that is in a `'dmriprep'` pipeline. Note that the pipeline name
is not necessarily the name of the folder it is in; the pipeline name is
defined in each pipeline's `dataset_description.json`. These data were
preprocessed with 'vistasoft', so this is the pipeline we'll point to
If we were using `'qsiprep'`, this is where we would pass that
string instead. If we did that, AFQ would look for a derivatives
folder called `'stanford_hardi/derivatives/qsiprep'` and find the
preprocessed DWI data within it. Finally, to speed things up
a bit, we also sub-sample the provided tractography. This is
done by defining the segmentation_params dictionary input.
To sub-sample to 10,000 streamlines, we define
`'nb_streamlines' = 10000`.

.. GENERATED FROM PYTHON SOURCE LINES 234-245

.. code-block:: default


    my_afq = GroupAFQ(
        bids_path,
        preproc_pipeline='vistasoft',
        bundle_info=bundle_info,
        custom_tractography_bids_filters={
            "suffix": "tractography",
            "scope": "my_tractography"
        },
        segmentation_params={'nb_streamlines': 10000})








.. GENERATED FROM PYTHON SOURCE LINES 246-249

Finally, to run the segmentation and extract tract profiles, we call
The `export_all` method. This creates all of the derivative outputs of
AFQ within the 'stanford_hardi/derivatives/afq' folder.

.. GENERATED FROM PYTHON SOURCE LINES 249-253

.. code-block:: default


    my_afq.export_all()






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
      0%|          | 0/2565 [00:00<?, ?it/s]      0%|          | 4/2565 [00:02<30:07,  1.42it/s]      1%|1         | 36/2565 [00:02<02:31, 16.75it/s]     20%|##        | 524/2565 [00:03<00:06, 325.44it/s]     60%|######    | 1548/2565 [00:03<00:00, 1087.11it/s]     80%|########  | 2060/2565 [00:03<00:00, 1427.63it/s]    100%|##########| 2565/2565 [00:03<00:00, 763.02it/s] 
      0%|          | 0/2440 [00:00<?, ?it/s]      4%|3         | 92/2440 [00:00<00:02, 876.70it/s]     31%|###1      | 764/2440 [00:00<00:00, 3516.74it/s]     63%|######2   | 1532/2440 [00:00<00:00, 4551.96it/s]     84%|########3 | 2044/2440 [00:00<00:00, 4222.01it/s]    100%|##########| 2440/2440 [00:00<00:00, 4752.26it/s]
      0%|          | 0/2195 [00:00<?, ?it/s]      4%|4         | 92/2195 [00:00<00:02, 879.34it/s]     35%|###4      | 764/2195 [00:00<00:00, 3930.90it/s]     70%|######9   | 1532/2195 [00:00<00:00, 5165.40it/s]     93%|#########3| 2044/2195 [00:00<00:00, 5072.76it/s]    100%|##########| 2195/2195 [00:00<00:00, 4982.29it/s]
      0%|          | 0/1900 [00:00<?, ?it/s]      5%|4         | 92/1900 [00:00<00:02, 883.62it/s]     40%|####      | 764/1900 [00:00<00:00, 3904.51it/s]     81%|########  | 1532/1900 [00:00<00:00, 5236.17it/s]    100%|##########| 1900/1900 [00:00<00:00, 5699.49it/s]
      0%|          | 0/1322 [00:00<?, ?it/s]      9%|9         | 124/1322 [00:00<00:01, 1195.91it/s]     77%|#######7  | 1020/1322 [00:00<00:00, 5591.12it/s]    100%|##########| 1322/1322 [00:00<00:00, 6377.05it/s]
      0%|          | 0/1245 [00:00<?, ?it/s]      5%|4         | 60/1245 [00:00<00:02, 571.89it/s]     82%|########1 | 1020/1245 [00:00<00:00, 5411.44it/s]    100%|##########| 1245/1245 [00:00<00:00, 5736.86it/s]
      0%|          | 0/1798 [00:00<?, ?it/s]      2%|2         | 44/1798 [00:00<00:04, 437.58it/s]     28%|##8       | 508/1798 [00:00<00:00, 2878.24it/s]     85%|########5 | 1532/1798 [00:00<00:00, 4762.13it/s]    100%|##########| 1798/1798 [00:00<00:00, 4860.86it/s]
      0%|          | 0/5 [00:00<?, ?it/s]     80%|########  | 4/5 [00:00<00:00, 34.11it/s]    100%|##########| 5/5 [00:00<00:00, 34.47it/s]
      0%|          | 0/5 [00:00<?, ?it/s]     80%|########  | 4/5 [00:00<00:00, 36.03it/s]    100%|##########| 5/5 [00:00<00:00, 36.08it/s]




.. GENERATED FROM PYTHON SOURCE LINES 254-260

A few common issues that can hinder BIDS from working properly are:

1. Faulty `dataset_description.json` file. You need to make sure that the
   file contains the right names for the pipeline. See above for an example
   of that.
2. File naming convention doesn't uniquely identify file with bids filters.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 23 minutes  4.716 seconds)


.. _sphx_glr_download_auto_examples_plot_bids_layout.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bids_layout.py <plot_bids_layout.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bids_layout.ipynb <plot_bids_layout.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
