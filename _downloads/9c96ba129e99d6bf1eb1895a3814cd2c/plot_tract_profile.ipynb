{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting tract profiles\n\nAn example of tracking and segmenting two tracts, and plotting their tract\nprofiles for FA (calculated with DTI). This example uses the Yeatman et al.\nwaypoint ROI approach, first described in [Yeatman2012]_ and further elaborated\nin [Yeatman2014]_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nibabel as nib\nimport dipy.data as dpd\nfrom dipy.data import fetcher\nfrom dipy.io.streamline import save_tractogram, load_tractogram\nfrom dipy.stats.analysis import afq_profile, gaussian_weights\nfrom dipy.io.stateful_tractogram import StatefulTractogram\nfrom dipy.io.stateful_tractogram import Space\nfrom dipy.align import affine_registration\n\nfrom AFQ import api\nimport AFQ.data as afd\nimport AFQ.tractography as aft\nimport AFQ.registration as reg\nimport AFQ.models.dti as dti\nimport AFQ.segmentation as seg\nfrom AFQ.utils.volume import transform_inverse_roi\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Target directory for this example's output files\nworking_dir = \"./tract_profile\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get example data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dpd.fetch_stanford_hardi()\nhardi_dir = op.join(fetcher.dipy_home, \"stanford_hardi\")\nhardi_fdata = op.join(hardi_dir, \"HARDI150.nii.gz\")\nhardi_fbval = op.join(hardi_dir, \"HARDI150.bval\")\nhardi_fbvec = op.join(hardi_dir, \"HARDI150.bvec\")\nimg = nib.load(hardi_fdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate DTI:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Calculating DTI...\")\nif not op.exists(op.join(working_dir, 'dti_FA.nii.gz')):\n    dti_params = dti.fit_dti(hardi_fdata, hardi_fbval, hardi_fbvec,\n                             out_dir=working_dir)\nelse:\n    dti_params = {'FA': op.join(working_dir, 'dti_FA.nii.gz'),\n                  'params': op.join(working_dir, 'dti_params.nii.gz')}\n\nFA_img = nib.load(dti_params['FA'])\nFA_data = FA_img.get_fdata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the individual data to a template:\nFor the purpose of bundle segmentation, the individual brain is registered to\nthe MNI T2 template. The waypoint ROIs used in segmentation are then each\nbrought into each subject's native space to test streamlines for whether they\nfulfill the segmentation criteria.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To find the right place for the waypoint ROIs, we calculate a non-linear\n    transformation between the individual's brain DWI measurement (the b0\n    measurements) and the MNI T2 template.\n    Before calculating this non-linear warping, we perform a pre-alignment\n    using an affine transformation.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Registering to template...\")\nMNI_T2_img = afd.read_mni_template()\n\nif not op.exists(op.join(working_dir, 'mapping.nii.gz')):\n    import dipy.core.gradients as dpg\n    gtab = dpg.gradient_table(hardi_fbval, hardi_fbvec)\n    b0 = np.mean(img.get_fdata()[..., gtab.b0s_mask], -1)\n    # Prealign using affine registration\n    _, prealign = affine_registration(\n        b0,\n        MNI_T2_img.get_fdata(),\n        img.affine,\n        MNI_T2_img.affine)\n\n    # Then register using a non-linear registration using the affine for\n    # prealignment\n    warped_hardi, mapping = reg.syn_register_dwi(hardi_fdata, gtab,\n                                                 prealign=prealign)\n    reg.write_mapping(mapping, op.join(working_dir, 'mapping.nii.gz'))\nelse:\n    mapping = reg.read_mapping(op.join(working_dir, 'mapping.nii.gz'),\n                               img, MNI_T2_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read in bundle specification\nThe waypoint ROIs, in addition to bundle probability maps are stored in this\ndata structure. The templates are first resampled into the MNI space, before\nthey are brought into the subject's individual native space.\nFor speed, we only segment two bundles here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundles = api.BundleDict([\"CST\", \"ARC\"], resample_to=MNI_T2_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking\nStreamlines are generate using DTI and a deterministic tractography\nalgorithm. For speed, we seed only within the waypoint ROIs for each bundle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Tracking...\")\nif not op.exists(op.join(working_dir, 'dti_streamlines.trk')):\n    seed_roi = np.zeros(img.shape[:-1])\n    for bundle in bundles:\n        for idx, roi in enumerate(bundles[bundle]['ROIs']):\n            if bundles[bundle]['rules'][idx]:\n                warped_roi = transform_inverse_roi(\n                    roi,\n                    mapping,\n                    bundle_name=bundle)\n\n                nib.save(nib.Nifti1Image(warped_roi.astype(float), img.affine),\n                         op.join(working_dir, f\"{bundle}_{idx+1}.nii.gz\"))\n                # Add voxels that aren't there yet:\n                seed_roi = np.logical_or(seed_roi, warped_roi)\n    nib.save(nib.Nifti1Image(\n        seed_roi.astype(float), img.affine),\n        op.join(working_dir, 'seed_roi.nii.gz'))\n    sft = aft.track(dti_params['params'], seed_mask=seed_roi,\n                    stop_mask=FA_data, stop_threshold=0.1)\n    save_tractogram(sft, op.join(working_dir, 'dti_streamlines.trk'),\n                    bbox_valid_check=False)\nelse:\n    sft = load_tractogram(op.join(working_dir, 'dti_streamlines.trk'), img)\n\nsft.to_vox()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segmentation\nIn this stage, streamlines are tested for several criteria: whether the\nprobability that they belong to a bundle is larger than a threshold (set to\n0,per default), whether they pass through inclusion ROIs and whether they do\nnot pass through exclusion ROIs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Segmenting fiber groups...\")\nsegmentation = seg.Segmentation(return_idx=True)\nsegmentation.segment(bundles,\n                     sft,\n                     fdata=hardi_fdata,\n                     fbval=hardi_fbval,\n                     fbvec=hardi_fbvec,\n                     mapping=mapping,\n                     reg_template=MNI_T2_img)\n\nfiber_groups = segmentation.fiber_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning\nEach fiber group is cleaned to exclude streamlines that are outliers in terms\nof their trajector and/or length.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Cleaning fiber groups...\")\nfor bundle in bundles:\n    print(f\"Cleaning {bundle}\")\n    print(f\"Before cleaning: {len(fiber_groups[bundle]['sl'])} streamlines\")\n    new_fibers, idx_in_bundle = seg.clean_bundle(\n        fiber_groups[bundle]['sl'],\n        return_idx=True)\n    print(f\"Afer cleaning: {len(new_fibers)} streamlines\")\n\n    idx_in_global = fiber_groups[bundle]['idx'][idx_in_bundle]\n    np.save(op.join(working_dir, f'{bundle}_idx.npy'), idx_in_global)\n    sft = StatefulTractogram(new_fibers.streamlines,\n                             img,\n                             Space.VOX)\n    sft.to_rasmm()\n    save_tractogram(sft, op.join(working_dir, f'{bundle}_afq.trk'),\n                    bbox_valid_check=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bundle profiles\nStreamlines are represented in the original diffusion space (`Space.VOX`) and\nscalar properties along the length of each bundle are queried from this\nscalar data. Here, the contribution of each streamline is weighted according\nto how representative this streamline is of the bundle overall.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Extracting tract profiles...\")\nfor bundle in bundles:\n    sft = load_tractogram(op.join(working_dir, f'{bundle}_afq.trk'),\n                          img, to_space=Space.VOX)\n    fig, ax = plt.subplots(1)\n    weights = gaussian_weights(sft.streamlines)\n    profile = afq_profile(FA_data, sft.streamlines,\n                          np.eye(4), weights=weights)\n    ax.plot(profile)\n    ax.set_title(bundle)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References:\n.. [Yeatman2012] Jason D Yeatman, Robert F Dougherty, Nathaniel J Myall,\n                 Brian A Wandell, Heidi M Feldman, \"Tract profiles of\n                 white matter properties: automating fiber-tract\n                 quantification\", PloS One, 7: e49790\n\n.. [Yeatman2014] Jason D Yeatman, Brian A Wandell, Aviv Mezer Feldman,\n                 \"Lifespan maturation and degeneration of human brain white\n                 matter\", Nature Communications 5: 4932\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}