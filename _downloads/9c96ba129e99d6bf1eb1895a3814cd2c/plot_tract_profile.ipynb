{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting tract profiles\n\nAn example of tracking and segmenting two tracts, and plotting their tract\nprofiles for FA (calculated with DTI). This example uses the Yeatman et al.\nwaypoint ROI approach, first described in [Yeatman2012]_ and further elaborated\nin [Yeatman2014]_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nibabel as nib\nimport dipy.data as dpd\nfrom dipy.data import fetcher\nfrom dipy.io.streamline import save_tractogram, load_tractogram\nfrom dipy.stats.analysis import afq_profile, gaussian_weights\nfrom dipy.io.stateful_tractogram import StatefulTractogram\nfrom dipy.io.stateful_tractogram import Space\n\nfrom AFQ import api\nimport AFQ.data as afd\nimport AFQ.tractography as aft\nimport AFQ.registration as reg\nimport AFQ.models.dti as dti\nimport AFQ.segmentation as seg\nfrom AFQ.utils.volume import patch_up_roi\n\nimport logging\nlogging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get example data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dpd.fetch_stanford_hardi()\nhardi_dir = op.join(fetcher.dipy_home, \"stanford_hardi\")\nhardi_fdata = op.join(hardi_dir, \"HARDI150.nii.gz\")\nhardi_fbval = op.join(hardi_dir, \"HARDI150.bval\")\nhardi_fbvec = op.join(hardi_dir, \"HARDI150.bvec\")\nimg = nib.load(hardi_fdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate DTI:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Calculating DTI...\")\nif not op.exists('./dti_FA.nii.gz'):\n    dti_params = dti.fit_dti(hardi_fdata, hardi_fbval, hardi_fbvec,\n                             out_dir='.')\nelse:\n    dti_params = {'FA': './dti_FA.nii.gz',\n                  'params': './dti_params.nii.gz'}\n\nFA_img = nib.load(dti_params['FA'])\nFA_data = FA_img.get_fdata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the individual data to a template:\nFor the purpose of bundle segmentation, the individual brain is registered\nto the MNI T2 template. The waypoint ROIs used in segmentation are then each\nbrought into each subject's native space to test streamlines for whether they\nfulfill the segmentation criteria.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Here, we calculate just a non-linear transformation between the\n    individual's brain and the MNI T2 template. In practice, it's a good idea\n    to also perform a pre-alignment using an affine transformation. We don't\n    do that here, but this is part of the full pipeline implemented in the\n    CLI.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Registering to template...\")\nMNI_T2_img = afd.read_mni_template()\nif not op.exists('mapping.nii.gz'):\n    import dipy.core.gradients as dpg\n    gtab = dpg.gradient_table(hardi_fbval, hardi_fbvec)\n\n    warped_hardi, mapping = reg.syn_register_dwi(hardi_fdata, gtab)\n    reg.write_mapping(mapping, './mapping.nii.gz')\nelse:\n    mapping = reg.read_mapping('./mapping.nii.gz', img, MNI_T2_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read in bundle specification\nThe waypoint ROIs, in addition to bundle probability maps are stored in this\ndata structure. The templates are first resampled into the MNI space, before\nthey are brought into the subject's individual native space.\nFor speed, we only segment two bundles here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundles = api.make_bundle_dict(bundle_names=[\"CST\", \"ARC\"],\n                               resample_to=MNI_T2_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking\nStreamlines are generate using DTI and a deterministic tractography\nalgorithm. For speed, we seed only within the waypoint ROIs for each bundle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Tracking...\")\nif not op.exists('dti_streamlines.trk'):\n    seed_roi = np.zeros(img.shape[:-1])\n    for bundle in bundles:\n        for idx, roi in enumerate(bundles[bundle]['ROIs']):\n            if bundles[bundle]['rules'][idx]:\n                warped_roi = patch_up_roi(\n                    mapping.transform_inverse(\n                        roi.get_fdata().astype(np.float32),\n                        interpolation='linear'),\n                        bundle_name=bundle)\n\n                nib.save(nib.Nifti1Image(warped_roi.astype(float), img.affine),\n                         f\"{bundle}_{idx+1}.nii.gz\")\n                # Add voxels that aren't there yet:\n                seed_roi = np.logical_or(seed_roi, warped_roi)\n    nib.save(nib.Nifti1Image(seed_roi.astype(float), img.affine),\n                             'seed_roi.nii.gz')\n    sft = aft.track(dti_params['params'], seed_mask=seed_roi,\n                    stop_mask=FA_data, stop_threshold=0.1)\n    save_tractogram(sft, './dti_streamlines.trk',\n                    bbox_valid_check=False)\nelse:\n    sft = load_tractogram('./dti_streamlines.trk', img)\n\nsft.to_vox()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segmentation\nIn this stage, streamlines are tested for several criteria: whether the\nprobability that they belong to a bundle is larger than a threshold (set to\n0,per default), whether they pass through inclusion ROIs and whether they do\nnot pass through exclusion ROIs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Segmenting fiber groups...\")\nsegmentation = seg.Segmentation(return_idx=True)\nsegmentation.segment(bundles,\n                     sft,\n                     fdata=hardi_fdata,\n                     fbval=hardi_fbval,\n                     fbvec=hardi_fbvec,\n                     mapping=mapping,\n                     reg_template=MNI_T2_img)\n\nfiber_groups = segmentation.fiber_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning\nEach fiber group is cleaned to exclude streamlines that are outliers in terms\nof their trajector and/or length.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Cleaning fiber groups...\")\nfor bundle in bundles:\n    print(f\"Cleaning {bundle}\")\n    print(f\"Before cleaning: {len(fiber_groups[bundle]['sl'])} streamlines\")\n    new_fibers, idx_in_bundle = seg.clean_bundle(\n        fiber_groups[bundle]['sl'],\n        return_idx=True)\n    print(f\"Afer cleaning: {len(new_fibers)} streamlines\")\n\n    idx_in_global = fiber_groups[bundle]['idx'][idx_in_bundle]\n    np.save(f'{bundle}_idx.npy', idx_in_global)\n    sft = StatefulTractogram(new_fibers.streamlines,\n                             img,\n                             Space.VOX)\n    sft.to_rasmm()\n    save_tractogram(sft, f'./{bundle}_afq.trk',\n                    bbox_valid_check=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bundle profiles\nStreamlines are represented in the original diffusion space (`Space.VOX`) and\nscalar properties along the length of each bundle are queried from this\nscalar data. Here, the contribution of each streamline is weighted according\nto how representative this streamline is of the bundle overall.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Extracting tract profiles...\")\nfor bundle in bundles:\n    sft = load_tractogram(f'./{bundle}_afq.trk', img, to_space=Space.VOX)\n    fig, ax = plt.subplots(1)\n    weights = gaussian_weights(sft.streamlines)\n    profile = afq_profile(FA_data, sft.streamlines,\n                          np.eye(4), weights=weights)\n    ax.plot(profile)\n    ax.set_title(bundle)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References:\n.. [Yeatman2012] Jason D Yeatman, Robert F Dougherty, Nathaniel J Myall,\n                 Brian A Wandell, Heidi M Feldman, \"Tract profiles of\n                 white matter properties: automating fiber-tract\n                 quantification\", PloS One, 7: e49790\n\n.. [Yeatman2014] Jason D Yeatman, Brian A Wandell, Aviv Mezer Feldman,\n                 \"Lifespan maturation and degeneration of human brain white\n                 matter\", Nature Communications 5: 4932\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}