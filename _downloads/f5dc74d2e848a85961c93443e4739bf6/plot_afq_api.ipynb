{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# AFQ API\n\nAn example using the AFQ API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\n\nimport matplotlib.pyplot as plt\nimport nibabel as nib\nimport plotly\n\nfrom AFQ.api.group import GroupAFQ\nimport AFQ.data as afd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get some example data\n\nRetrieves High angular resolution diffusion imaging (HARDI) dataset from\nStanford's Vista Lab\n\n  see https://purl.stanford.edu/ng782rw8378 for details on dataset.\n\nThe data for the first subject and first session are downloaded locally\n(by default into the users home directory) under:\n\n  ``.dipy/stanford_hardi/``\n\nAnatomical data (``anat``) and Diffusion-weighted imaging data (``dwi``) are\nthen extracted, formatted to be BIDS compliant, and placed in the AFQ\ndata directory (by default in the users home directory) under:\n\n  ``AFQ_data/stanford_hardi/``\n\nThis data represents the required preprocessed diffusion data necessary for\nintializing the AFQ object (which we will do next)\n\nThe clear_previous_afq is used to remove any previous runs of the afq object\nstored in the AFQ_data/stanford_hardi/ BIDS directory. Set it to false if\nyou want to use the results of previous runs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "afd.organize_stanford_data(clear_previous_afq=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize an AFQ object:\n\nCreates an AFQ object, that encapsulates tractometry. This object can be\nused to manage the entire AFQ pipeline, including:\n\n- Tractography\n- Registration\n- Segmentation\n- Cleaning\n- Profiling\n- Visualization\n\nIn this example we will load the subjects session data from the previous step\nusing the default AFQ parameters.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The first time intializing the AFQ object will download necessary\n   waypoint regions of interest (ROIs) templates into AFQ data directory:</p></div>\n\n- Human corpus callosum templates: ``AFQ_data/callosum_templates/``\n\n  see https://digital.lib.washington.edu/researchworks/handle/1773/34926\n\n- Tract probability maps: ``AFQ_data/templates/``\n\n  see https://figshare.com/articles/Tract_probability_maps_for_automated_fiber_quantification/6270434  # noqa\n\nThese waypoints ROIs will used to identify the desired white matter tracts.\n\nThis will also create an output folder for the corresponding AFQ derivatives\nin the AFQ data directory: ``AFQ_data/stanford_hardi/derivatives/afq/``\n\nTo initialize this object we will pass in the path location to our BIDS\ncompliant data.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>As noted above, the Stanford HARDI data contains anatomical and\n   diffusion weighted imaging (dwi) data. In this example, we are interested\n   in the vistasoft dwi. For our dataset the `dmriprep` is optional, but\n   we have included it to make the initialization more explicit.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We will also be using plotly to generate an interactive visualization.\n   So we will specify plotly_no_gif as the visualization backend.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "myafq = GroupAFQ(\n    bids_path=op.join(afd.afq_home, 'stanford_hardi'),\n    preproc_pipeline='vistasoft',\n    viz_backend_spec='plotly_no_gif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading in DTI FA (Diffusion Tensor Imaging Fractional Anisotropy)\nThe AFQ object holds a table with file names to various data derivatives.\n\nFor example, the file where the FA computed from DTI is stored can be\nretrieved by inspecting the ``dti_fa`` property. The measures are stored\nin a series, and since we only have one subject and one session we will\naccess the first (and only) file name from the example data.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The AFQ API computes quantities lazily. This means that DTI parameters\n   are not computed until they are required. This means that the first\n   line below is the one that requires time.</p></div>\n\nWe will then use `nibabel` to load the deriviative file and retrieve the\ndata array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "FA_fname = myafq.dti_fa[\"01\"]\nFA_img = nib.load(FA_fname)\nFA = FA_img.get_fdata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the result with Matplotlib\nAt this point `FA` is an array, and we can use standard Python tools to\nvisualize it or perform additional computations with it.\n\nIn this case we are going to take an axial slice halfway through the\nFA data array and plot using a sequential color map.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The data array is structured as a xyz coordinate system.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1)\nax.matshow(FA[:, :, FA.shape[-1] // 2], cmap='viridis')\nax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing bundles and tract profiles:\nThe pyAFQ API provides several ways to visualize bundles and profiles.\n\nFirst, we will run a function that exports an html file that contains\nan interactive visualization of the bundles that are segmented.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>By default we resample a 100 points within a bundle, however to reduce\n   processing time we will only resample 50 points.</p></div>\n\nOnce it is done running, it should pop a browser window open and let you\ninteract with the bundles.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Running the code below triggers the full pipeline of operations\n   leading to the computation of the tract profiles. Therefore, it\n   takes a little while to run (about 40 minutes, typically).</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You can hide or show a bundle by clicking the legend, or select a\n   single bundle by double clicking the legend. The interactive\n   visualization will also all you to pan, zoom, and rotate.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundle_html = myafq.all_bundles_figure\nplotly.io.show(bundle_html[\"01\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also visualize the tract profiles in all of the bundles. These\nplots show both FA (left) and MD (right) layed out anatomically.\nTo make this plots, it is required that you install with\n`pip install pyAFQ[plot]` so that you have the necessary dependencies.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_files = myafq.tract_profile_plots[\"01\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure:: {{ fig_files[0] }}\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}