{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting the Optic Radiations\n\npyAFQ is designed to be customizable. This example shows how\nyou can customize it to define a new bundle based\non both waypoint ROIs of your design, as well as endpoint\nROIs of your design.\n\nFor now, this is a hypothetical example, as we do not yet\nprovide these ROIs as part of the software.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dipy.data import get_fnames\nimport os.path as op\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport nibabel as nib\nimport dipy.data as dpd\nfrom dipy.data import fetcher\nfrom dipy.io.streamline import save_tractogram, load_tractogram\nfrom dipy.stats.analysis import afq_profile, gaussian_weights\nfrom dipy.io.stateful_tractogram import StatefulTractogram\nfrom dipy.io.stateful_tractogram import Space\nfrom dipy.reconst import shm\nfrom dipy.align import affine_registration, resample\n\nimport AFQ.data as afd\nimport AFQ.tractography as aft\nimport AFQ.registration as reg\nimport AFQ.models.dti as dti\nimport AFQ.models.csd as csd\nimport AFQ.segmentation as seg\nfrom AFQ.utils.volume import transform_inverse_roi\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\n# Target directory for this example's output files\nworking_dir = \"./optic_radiations\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get example data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dpd.fetch_stanford_hardi()\nhardi_dir = op.join(fetcher.dipy_home, \"stanford_hardi\")\nhardi_fdata = op.join(hardi_dir, \"HARDI150.nii.gz\")\nhardi_fbval = op.join(hardi_dir, \"HARDI150.bval\")\nhardi_fbvec = op.join(hardi_dir, \"HARDI150.bvec\")\nimg = nib.load(hardi_fdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate DTI:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Calculating DTI...\")\nif not op.exists(op.join(working_dir, 'dti_FA.nii.gz')):\n    dti_params = dti.fit_dti(hardi_fdata, hardi_fbval, hardi_fbvec,\n                             out_dir=working_dir)\nelse:\n    dti_params = {'FA': op.join(working_dir, 'dti_FA.nii.gz'),\n                  'params': op.join(working_dir, 'dti_params.nii.gz')}\n\nFA_img = nib.load(dti_params['FA'])\nFA_data = FA_img.get_fdata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate CSD:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Calculating CSD...\")\nif not op.exists(op.join(working_dir, 'csd_sh_coeff.nii.gz')):\n    sh_coeff = csd.fit_csd(hardi_fdata, hardi_fbval, hardi_fbvec,\n                           sh_order=4, out_dir=working_dir)\nelse:\n    sh_coeff = op.join(working_dir, \"csd_sh_coeff.nii.gz\")\n\napm = shm.anisotropic_power(nib.load(sh_coeff).get_fdata())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the individual data to a template:\nFor the purpose of bundle segmentation, the individual brain is registered to\nthe MNI T1 template. The waypoint ROIs used in segmentation are then each\nbrought into each subject's native space to test streamlines for whether they\nfulfill the segmentation criteria.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To find the right place for the waypoint ROIs, we calculate a non-linear\n    transformation between the individual's brain DWI measurement (the b0\n    measurements) and the MNI T1 template.\n    Before calculating this non-linear warping, we perform a pre-alignment\n    using an affine transformation.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Registering to template...\")\n\nMNI_T1w_img = afd.read_mni_template(weight=\"T1w\")\n\nif not op.exists(op.join(working_dir, 'mapping.nii.gz')):\n    import dipy.core.gradients as dpg\n    gtab = dpg.gradient_table(hardi_fbval, hardi_fbvec)\n    # Prealign using affine registration\n    _, prealign = affine_registration(\n        apm,\n        MNI_T1w_img.get_fdata(),\n        img.affine,\n        MNI_T1w_img.affine)\n\n    # Then register using a non-linear registration using the affine for\n    # prealignment\n    warped_hardi, mapping = reg.syn_register_dwi(hardi_fdata, gtab,\n                                                 prealign=prealign)\n    reg.write_mapping(mapping, op.join(working_dir, 'mapping.nii.gz'))\nelse:\n    mapping = reg.read_mapping(op.join(working_dir, 'mapping.nii.gz'),\n                               img, MNI_T1w_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bundle specification\n\nHere, a bundle specification is defined as a series of waypoint ROIs.\nFor each hemisphere, two ROIs are inclusion ROIs and three ROIs are\nexclusion ROIs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "roi_folder = op.join(op.expanduser('~'), \"AFQ_Data\", \"visual\")\nwaypoint_folder = op.join(roi_folder, \"waypoint\")\n\nwaypoint_roi_fnames = [\n    \"left_OR_1.nii.gz\",\n    \"left_OR_2.nii.gz\",\n    \"left_OP_MNI.nii.gz\",\n    \"left_TP_MNI.nii.gz\",\n    \"left_pos_thal_MNI.nii.gz\",\n    \"right_OR_1.nii.gz\",\n    \"right_OR_2.nii.gz\",\n    \"right_pos_thal_MNI.nii.gz\",\n    \"right_OP_MNI.nii.gz\",\n    \"right_TP_MNI.nii.gz\"]\n\nwaypoint_rois = {}\n\nfor fname in waypoint_roi_fnames:\n    waypoint_rois[fname.split('.')[0]] = afd.read_resample_roi(\n        op.join(waypoint_folder, fname))\n\nbundles = {\n    \"L_OR\": {\n        \"ROIs\": [waypoint_rois[\"left_OR_1\"],\n                 waypoint_rois[\"left_OR_2\"],\n                 waypoint_rois[\"left_OP_MNI\"],\n                 waypoint_rois[\"left_TP_MNI\"],\n                 waypoint_rois[\"left_pos_thal_MNI\"]],\n        \"rules\": [True, True, False, False, False],\n        \"cross_midline\": False,\n        \"uid\": 1\n        },\n    \"R_OR\": {\n        \"ROIs\": [waypoint_rois[\"right_OR_1\"],\n                 waypoint_rois[\"right_OR_2\"],\n                 waypoint_rois[\"right_OP_MNI\"],\n                 waypoint_rois[\"right_TP_MNI\"],\n                 waypoint_rois[\"right_pos_thal_MNI\"]],\n        \"rules\": [True, True, False, False, False],\n        \"cross_midline\": False,\n        \"uid\": 2\n        }\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Endpoints\nIn addition to the waypoint ROIs, we will customize the endpoint ROIs\nused for filtering the streamlines that are selected based on the\nwaypoint ROIs defined above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "endpoint_folder = op.join(roi_folder, \"endpoint\")\n\nendpoint_spec = {\n    \"L_OR\": {\n        \"startpoint\": nib.load(op.join(endpoint_folder,\n                                       'left_thal_MNI.nii.gz')),\n        \"endpoint\": nib.load(op.join(endpoint_folder,\n                                     'left_V1_MNI.nii.gz'))},\n    \"R_OR\": {\n        \"startpoint\": nib.load(op.join(endpoint_folder,\n                                       'right_thal_MNI.nii.gz')),\n        \"endpoint\": nib.load(op.join(endpoint_folder,\n                                     'right_V1_MNI.nii.gz'))}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking\nWe will use PFT and generate a large number of streamlines from seeds\nplaced only within the inclusion ROIs. This allows us to oversample that\npart of the brain, without having to deal with very large tractograms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f_pve_csf, f_pve_gm, f_pve_wm = get_fnames('stanford_pve_maps')\n\npve_csf = nib.load(f_pve_csf)\npve_gm = nib.load(f_pve_gm)\npve_wm = nib.load(f_pve_wm)\n\nprint(\"Tracking...\")\nif not op.exists(op.join(working_dir, 'pft_streamlines.trk')):\n    seed_roi = np.zeros(img.shape[:-1])\n    for bundle in bundles:\n        for idx, roi in enumerate(bundles[bundle]['ROIs']):\n            warped_roi = transform_inverse_roi(\n                roi,\n                mapping,\n                bundle_name=bundle)\n            print(roi)\n            nib.save(nib.Nifti1Image(warped_roi.astype(float), img.affine),\n                     op.join(working_dir, f\"{bundle}_{idx+1}.nii.gz\"))\n\n            # Add voxels that aren't there yet:\n            if bundles[bundle]['rules'][idx]:\n                seed_roi = np.logical_or(seed_roi, warped_roi)\n\n        for ii, pp in enumerate(endpoint_spec[bundle].keys()):\n            roi = endpoint_spec[bundle][pp]\n            roi = resample(\n                roi.get_fdata(),\n                MNI_T1w_img,\n                roi.affine,\n                MNI_T1w_img.affine).get_fdata()\n\n            warped_roi = transform_inverse_roi(\n                roi,\n                mapping,\n                bundle_name=bundle)\n\n            nib.save(nib.Nifti1Image(warped_roi.astype(float), img.affine),\n                     op.join(working_dir, f\"{bundle}_{pp}.nii.gz\"))\n\n    nib.save(nib.Nifti1Image(seed_roi.astype(float), img.affine),\n             op.join(working_dir, 'seed_roi.nii.gz'))\n\n    sft = aft.track(sh_coeff,\n                    seed_mask=seed_roi,\n                    n_seeds=5,\n                    tracker=\"pft\",\n                    stop_mask=(pve_wm, pve_gm, pve_csf),\n                    stop_threshold=\"ACT\",\n                    directions=\"prob\",\n                    odf_model=\"CSD\")\n\n    save_tractogram(sft, op.join(working_dir, 'pft_streamlines.trk'),\n                    bbox_valid_check=False)\nelse:\n    sft = load_tractogram(op.join(working_dir, 'pft_streamlines.trk'), img)\n\nsft.to_vox()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segmentation\nWe run the segmentation using both the ``bundles`` and the\n``endpoint_spec`` we defined above. In this particular case, we set a\nrather lenient criterion for endpoint filtering, by changing from the\ndefault value of ``dist_to_atlas`` (4 mm) to 5 mm.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Segmenting fiber groups...\")\nsegmentation = seg.Segmentation(return_idx=True,\n                                dist_to_atlas=5)\nsegmentation.segment(bundles,\n                     sft,\n                     fdata=hardi_fdata,\n                     fbval=hardi_fbval,\n                     fbvec=hardi_fbvec,\n                     mapping=mapping,\n                     reg_template=MNI_T1w_img,\n                     endpoint_dict=endpoint_spec)\n\nfiber_groups = segmentation.fiber_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning\nWe proceed to clean outliers and save out trk files with the bundles.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Cleaning fiber groups...\")\nfor bundle in bundles:\n    print(f\"Cleaning {bundle}\")\n    print(f\"Before cleaning: {len(fiber_groups[bundle]['sl'])} streamlines\")\n    new_fibers, idx_in_bundle = seg.clean_bundle(\n        fiber_groups[bundle]['sl'],\n        return_idx=True)\n    print(f\"Afer cleaning: {len(new_fibers)} streamlines\")\n    new_fibers = fiber_groups[bundle]['sl']\n    idx_in_global = fiber_groups[bundle]['idx'][idx_in_bundle]\n    np.save(op.join(working_dir, f'{bundle}_idx.npy'), idx_in_global)\n    sft = StatefulTractogram(new_fibers.streamlines,\n                             img,\n                             Space.VOX)\n    sft.to_rasmm()\n    save_tractogram(sft, op.join(working_dir, f'{bundle}_afq.trk'),\n                    bbox_valid_check=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bundle profiles\nFinally, we can extract and plot bundle profiles.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Extracting tract profiles...\")\nfor bundle in bundles:\n    sft = load_tractogram(op.join(working_dir, f'{bundle}_afq.trk'),\n                          img, to_space=Space.VOX)\n    fig, ax = plt.subplots(1)\n    weights = gaussian_weights(sft.streamlines)\n    profile = afq_profile(FA_data, sft.streamlines,\n                          np.eye(4), weights=weights)\n    ax.plot(profile)\n    ax.set_title(bundle)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References:\n.. [Yeatman2012] Jason D Yeatman, Robert F Dougherty, Nathaniel J Myall,\n                 Brian A Wandell, Heidi M Feldman, \"Tract profiles of\n                 white matter properties: automating fiber-tract\n                 quantification\", PloS One, 7: e49790\n\n.. [Yeatman2014] Jason D Yeatman, Brian A Wandell, Aviv Mezer Feldman,\n                 \"Lifespan maturation and degeneration of human brain white\n                 matter\", Nature Communications 5: 4932\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}